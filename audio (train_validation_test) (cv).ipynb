{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import import_ipynb\n",
    "import preprocessor\n",
    "import display\n",
    "import classifier\n",
    "import csv_file_io\n",
    "import datetime\n",
    "\n",
    "\n",
    "PROJECT_HOME = './'\n",
    "# DRONE = 'Inspire2' # 'Bebop2', 'Spark', 'MavicPro', 'Phantom4', 'Matrice100', 'MavicAir', 'AutelEVO', 'Inspire2', 'JME', 'ParrotAnafi']\n",
    "# DATASET_DIR = PROJECT_HOME + 'dataset/validation/Inspire2/Inspire2_validation_File3.wav'\n",
    "RESULT_FILE_DIR = PROJECT_HOME + 'results/'\n",
    "DATASET_FILE_DIR = PROJECT_HOME + 'results/dataset/'\n",
    "TRAINING_DATASET_DIR = PROJECT_HOME + 'dataset/1. training/'\n",
    "VALIDATION_DATASET_DIR = PROJECT_HOME + 'dataset/2. validation/'\n",
    "TEST_DATASET_DIR = PROJECT_HOME + 'dataset/3. test/'\n",
    "TRAINING_VALIDATION_DATASET_DIR = PROJECT_HOME + 'dataset/4. training_validation/'\n",
    "TRAINING_VALIDATION_TEST_DATASET_DIR = PROJECT_HOME + 'dataset/5. training_validation_test/'\n",
    "SEGMENTATION_DATASET_DIR = PROJECT_HOME + 'dataset/6. segmentation/'\n",
    "SEGMENTATION_TEST_DATASET_DIR = PROJECT_HOME + 'dataset/7. segmentation(test)/'\n",
    "\n",
    "# now = datetime.datetime.now()\n",
    "# now_date_time = now.strftime('%Y%m%d_%H%M%S')[2:]\n",
    "\n",
    "N_MFCC = 80\n",
    "\n",
    "RESULT_FILE_NAME = \"[Cross-Validation-\" + str(N_MFCC) + \"] result_\"\n",
    "\n",
    "SAMPLE_RATE = 44100\n",
    "FIG_SIZE = (15,5)\n",
    "\n",
    "FRAME_LENGTH = 0.250 # 250 ms\n",
    "FRAME_STRIDE = 0.250 # same with frame_length for 0% overlap\n",
    "\n",
    "DIGITS = 3\n",
    "\n",
    "b_visualizing = False\n",
    "\n",
    "def save_cv_classification_performance(kernel: str, report_dict: dict, acc: float, date_time: datetime, standardscaler: bool):\n",
    "    if standardscaler == True:\n",
    "        name = '_scale(O)_'\n",
    "    else:\n",
    "        name = '_scale(X)_'\n",
    "\n",
    "    file_name = RESULT_FILE_NAME.split('_')[0] + name\n",
    "    f = csv_file_io.open_csv(RESULT_FILE_DIR + file_name + date_time + '.csv', 'a')\n",
    "    csv_file_io.write_csv_data(f, [kernel + \"'s Cross-validation report\"])\n",
    "    csv_file_io.write_csv_data(f, ['', 'fit_time', 'score_time', 'test_score'])\n",
    "    \n",
    "    for i in range(0, len(report_dict['test_score'])):\n",
    "        csv_file_io.write_csv_data(f, [i, report_dict['fit_time'][i], report_dict['score_time'][i],  report_dict['test_score'][i]])    \n",
    "        \n",
    "    csv_file_io.write_csv_data(f, ['', '', 'accuracy', acc])    \n",
    "    csv_file_io.write_csv_data(f, [])\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_integrated_train_validation_test_signal = preprocessor.get_integrated_signal(SEGMENTATION_DATASET_DIR, type='SEGMENTATION')\n",
    "\n",
    "# Visualizing Audio (waveform and power spectrum)\n",
    "if b_visualizing == True:\n",
    "    for key, val in dict_integrated_train_validation_test_signal.items():\n",
    "        display.display_waveshow(val, key + \"'s Training+Validation+Test Signal's Waveform\")\n",
    "        display.display_power_spectrum(val, key + \"'s Training+Validation+Test Signal's Power Spectrum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction (MFCC)\n",
    "n_fft = int(SAMPLE_RATE * FRAME_LENGTH) # length of the FFT window, frame 하나당 sample의 수 / n_fft=2048, n_fft = int(SAMPLE_RATE * FRAME_LENGTH)\n",
    "hop_length = int(SAMPLE_RATE * FRAME_STRIDE) # number of samples between successive frames / hop_length=512, hop_length = int(SAMPLE_RATE * FRAME_STRIDE)\n",
    "n_mels = 128\n",
    "f_max = 8000\n",
    "\n",
    "dict_melspectrogram_train_validation_test_signal = {}\n",
    "for key, val in dict_integrated_train_validation_test_signal.items():    \n",
    "    dict_melspectrogram_train_validation_test_signal[key] = librosa.feature.melspectrogram(val, sr=SAMPLE_RATE, n_mels=n_mels, fmax=f_max, n_fft=n_fft, hop_length=hop_length)    \n",
    "\n",
    "dict_mfccs_train_validation_test_signal = {}\n",
    "for key, val in dict_melspectrogram_train_validation_test_signal.items():\n",
    "    dict_mfccs_train_validation_test_signal[key] = librosa.feature.mfcc(S=librosa.power_to_db(val), sr=SAMPLE_RATE, n_mfcc=N_MFCC)\n",
    "\n",
    "# print(dict_melspectrogram_train_validation_test_signal['AutelEVO'].shape)\n",
    "# print(dict_mfccs_train_validation_test_signal['AutelEVO'].shape)\n",
    "\n",
    "if b_visualizing == True:\n",
    "    for key, val in dict_mfccs_train_validation_test_signal.items():\n",
    "        display.display_mfccs(val,  \"'s Training+Validation+Test Signal's MFCCs\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_train_validation_test_data = None\n",
    "arr_train_validation_test_target = None\n",
    "\n",
    "for key, val in dict_mfccs_train_validation_test_signal.items():    \n",
    "    arr_mfccs_data = val.transpose()    \n",
    "    arr_target = np.full((arr_mfccs_data.shape[0], 1), key)   \n",
    "\n",
    "    if arr_train_validation_test_data is None:\n",
    "        arr_train_validation_test_data = arr_mfccs_data\n",
    "        arr_train_validation_test_target = arr_target        \n",
    "    else:       \n",
    "        arr_train_validation_test_data = np.vstack((arr_train_validation_test_data, arr_mfccs_data))\n",
    "        arr_train_validation_test_target = np.vstack((arr_train_validation_test_target, arr_target))\n",
    "\n",
    "print(\"Training+Validation+Test data / target : \", arr_train_validation_test_data.shape, arr_train_validation_test_target.shape)\n",
    "# ararr_train_validation_test_data_target = np.hstack((arr_train_validation_test_data, arr_train_validation_test_target))\n",
    "# np.savetxt(DATASET_FILE_DIR + DATASET_FILE_NAME + now_date_time + '.csv', ararr_train_validation_test_data_target, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "now_date_time = now.strftime('%Y%m%d_%H%M%S')[2:]\n",
    "\n",
    "CV = 10\n",
    "b_standardscaler = True\n",
    "\n",
    "report, acc = classifier.cross_validation_svm(\"linear\", CV, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "save_cv_classification_performance(\"linear\", report, acc, now_date_time, b_standardscaler)\n",
    "\n",
    "report, acc = classifier.cross_validation_svm(\"LinearSVC\", CV, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "save_cv_classification_performance(\"LinearSVC\", report, acc, now_date_time, b_standardscaler)\n",
    "\n",
    "report, acc = classifier.cross_validation_svm(\"rbf\", CV, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "save_cv_classification_performance(\"rbf\", report, acc, now_date_time, b_standardscaler)\n",
    "\n",
    "report, acc = classifier.cross_validation_svm(\"poly\", CV, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "save_cv_classification_performance(\"poly\", report, acc, now_date_time, b_standardscaler)\n",
    "\n",
    "report, acc = classifier.cross_validation_svm(\"sigmoid\", CV, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "save_cv_classification_performance(\"sigmoid\", report, acc, now_date_time, b_standardscaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "now_date_time = now.strftime('%Y%m%d_%H%M%S')[2:]\n",
    "\n",
    "CV = 10\n",
    "b_standardscaler = False\n",
    "\n",
    "report, acc = classifier.cross_validation_svm(\"linear\", CV, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "save_cv_classification_performance(\"linear\", report, acc, now_date_time, b_standardscaler)\n",
    "\n",
    "report, acc = classifier.cross_validation_svm(\"LinearSVC\", CV, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "save_cv_classification_performance(\"LinearSVC\", report, acc, now_date_time, b_standardscaler)\n",
    "\n",
    "report, acc = classifier.cross_validation_svm(\"rbf\", CV, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "save_cv_classification_performance(\"rbf\", report, acc, now_date_time, b_standardscaler)\n",
    "\n",
    "report, acc = classifier.cross_validation_svm(\"poly\", CV, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "save_cv_classification_performance(\"poly\", report, acc, now_date_time, b_standardscaler)\n",
    "\n",
    "report, acc = classifier.cross_validation_svm(\"sigmoid\", CV, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "save_cv_classification_performance(\"sigmoid\", report, acc, now_date_time, b_standardscaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16 (default, Jan 17 2023, 22:25:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
