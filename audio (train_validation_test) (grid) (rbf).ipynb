{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import import_ipynb\n",
    "import preprocessor\n",
    "import display\n",
    "import classifier\n",
    "import csv_file_io\n",
    "import datetime\n",
    "\n",
    "PROJECT_HOME = './'\n",
    "# DRONE = 'Inspire2' # 'Bebop2', 'Spark', 'MavicPro', 'Phantom4', 'Matrice100', 'MavicAir', 'AutelEVO', 'Inspire2', 'JME', 'ParrotAnafi']\n",
    "# DATASET_DIR = PROJECT_HOME + 'dataset/validation/Inspire2/Inspire2_validation_File3.wav'\n",
    "RESULT_FILE_DIR = PROJECT_HOME + 'results/'\n",
    "# DATASET_FILE_DIR = PROJECT_HOME + 'results/dataset/'\n",
    "# TRAINING_DATASET_DIR = PROJECT_HOME + 'dataset/1. training/'\n",
    "# VALIDATION_DATASET_DIR = PROJECT_HOME + 'dataset/2. validation/'\n",
    "# TEST_DATASET_DIR = PROJECT_HOME + 'dataset/3. test/'\n",
    "# TRAINING_VALIDATION_DATASET_DIR = PROJECT_HOME + 'dataset/4. training_validation/'\n",
    "# TRAINING_VALIDATION_TEST_DATASET_DIR = PROJECT_HOME + 'dataset/5. training_validation_test/'\n",
    "SEGMENTATION_DATASET_DIR = PROJECT_HOME + 'dataset/10. segmentation (w.o)/'\n",
    "# SEGMENTATION_TEST_DATASET_DIR = PROJECT_HOME + 'dataset/7. segmentation(test)/'\n",
    "\n",
    "# now = datetime.datetime.now()\n",
    "# now_date_time = now.strftime('%Y%m%d_%H%M%S')[2:]\n",
    "\n",
    "N_MFCC = 40\n",
    "KERNEL = \"rbf\" # \"rbf\", \"poly\", \"sigmoid\", \"LinearSVC\"\n",
    "\n",
    "RESULT_FILE_NAME = \"[gridsearchCV (\" + KERNEL + \")-\" + str(N_MFCC) + \"] result_\"\n",
    "\n",
    "SAMPLE_RATE = 44100\n",
    "FIG_SIZE = (15,5)\n",
    "\n",
    "FRAME_LENGTH = 0.250 # 250 ms\n",
    "FRAME_STRIDE = 0.250 # same with frame_length for 0% overlap\n",
    "\n",
    "DIGITS = 3\n",
    "\n",
    "b_visualizing = False\n",
    "\n",
    "def save_grid_classification_performance(report_dict: dict, params: dict, date_time: datetime, standardscaler: bool):        \n",
    "\n",
    "    if standardscaler == True:\n",
    "        f = csv_file_io.open_csv(RESULT_FILE_DIR + RESULT_FILE_NAME + date_time + '.csv', 'a')\n",
    "        csv_file_io.write_csv_data(f, [KERNEL + \"'s gridsearchCV report (scale O)\"])\n",
    "        f.close()\n",
    "\n",
    "        report_dict.to_csv(RESULT_FILE_DIR + RESULT_FILE_NAME + date_time + '.csv', mode='a')\n",
    "\n",
    "        f = csv_file_io.open_csv(RESULT_FILE_DIR + RESULT_FILE_NAME + date_time + '.csv', 'a')    \n",
    "\n",
    "        if KERNEL == \"linear\":\n",
    "            csv_file_io.write_csv_data(f, ['params', params['model__C'], params['model__max_iter']])\n",
    "        elif KERNEL == \"rbf\":\n",
    "            csv_file_io.write_csv_data(f, ['params', params['model__C'], params['model__gamma'], params['model__max_iter']])\n",
    "        elif KERNEL == \"poly\":\n",
    "            csv_file_io.write_csv_data(f, ['params', params['model__C'], params['model__degree'], params['model__gamma'], params['model__max_iter']])\n",
    "        elif KERNEL == \"sigmoid\":\n",
    "            csv_file_io.write_csv_data(f, ['params', params['model__C'], params['model__gamma'], params['model__max_iter']])\n",
    "        elif KERNEL == \"LinearSVC\":\n",
    "            csv_file_io.write_csv_data(f, ['params', params['model__C'], params['model__max_iter']])\n",
    "    \n",
    "        csv_file_io.write_csv_data(f, [])\n",
    "        f.close()   \n",
    "\n",
    "    else:        \n",
    "        f = csv_file_io.open_csv(RESULT_FILE_DIR + RESULT_FILE_NAME + date_time + '.csv', 'a')\n",
    "        csv_file_io.write_csv_data(f, [KERNEL + \"'s gridsearchCV report (scale X)\"])\n",
    "        f.close()\n",
    "\n",
    "        report_dict.to_csv(RESULT_FILE_DIR + RESULT_FILE_NAME + date_time + '.csv', mode='a')\n",
    "\n",
    "        f = csv_file_io.open_csv(RESULT_FILE_DIR + RESULT_FILE_NAME + date_time + '.csv', 'a')    \n",
    "\n",
    "        if KERNEL == \"linear\":\n",
    "            csv_file_io.write_csv_data(f, ['params', params['C'], params['max_iter']])\n",
    "        elif KERNEL == \"rbf\":\n",
    "            csv_file_io.write_csv_data(f, ['params', params['C'], params['gamma'], params['max_iter']])\n",
    "        elif KERNEL == \"poly\":\n",
    "            csv_file_io.write_csv_data(f, ['params', params['C'], params['degree'], params['gamma'], params['max_iter']])\n",
    "        elif KERNEL == \"sigmoid\":\n",
    "            csv_file_io.write_csv_data(f, ['params', params['C'], params['gamma'], params['max_iter']])\n",
    "        elif KERNEL == \"LinearSVC\":\n",
    "            csv_file_io.write_csv_data(f, ['params', params['C'], params['max_iter']])\n",
    "    \n",
    "        csv_file_io.write_csv_data(f, [])\n",
    "        f.close()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_integrated_train_validation_test_signal = preprocessor.get_integrated_signal(SEGMENTATION_DATASET_DIR, type='SEGMENTATION')\n",
    "\n",
    "# Visualizing Audio (waveform and power spectrum)\n",
    "if b_visualizing == True:\n",
    "    for key, val in dict_integrated_train_validation_test_signal.items():\n",
    "        display.display_waveshow(val, key + \"'s Training+Validation+Test Signal's Waveform\")\n",
    "        display.display_power_spectrum(val, key + \"'s Training+Validation+Test Signal's Power Spectrum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction (MFCC)\n",
    "n_fft = int(SAMPLE_RATE * FRAME_LENGTH) # length of the FFT window, frame 하나당 sample의 수 / n_fft=2048, n_fft = int(SAMPLE_RATE * FRAME_LENGTH)\n",
    "hop_length = int(SAMPLE_RATE * FRAME_STRIDE) # number of samples between successive frames / hop_length=512, hop_length = int(SAMPLE_RATE * FRAME_STRIDE)\n",
    "n_mels = 128\n",
    "f_max = 8000\n",
    "\n",
    "dict_melspectrogram_train_validation_test_signal = {}\n",
    "for key, val in dict_integrated_train_validation_test_signal.items():    \n",
    "    dict_melspectrogram_train_validation_test_signal[key] = librosa.feature.melspectrogram(val, sr=SAMPLE_RATE, n_mels=n_mels, fmax=f_max, n_fft=n_fft, hop_length=hop_length)    \n",
    "\n",
    "dict_mfccs_train_validation_test_signal = {}\n",
    "for key, val in dict_melspectrogram_train_validation_test_signal.items():\n",
    "    dict_mfccs_train_validation_test_signal[key] = librosa.feature.mfcc(S=librosa.power_to_db(val), sr=SAMPLE_RATE, n_mfcc=N_MFCC)\n",
    "\n",
    "# print(dict_melspectrogram_train_validation_test_signal['AutelEVO'].shape)\n",
    "# print(dict_mfccs_train_validation_test_signal['AutelEVO'].shape)\n",
    "\n",
    "if b_visualizing == True:\n",
    "    for key, val in dict_mfccs_train_validation_test_signal.items():\n",
    "        display.display_mfccs(val, key +  \"'s Training+Validation+Test Signal's MFCCs\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_train_validation_test_data = None\n",
    "arr_train_validation_test_target = None\n",
    "\n",
    "for key, val in dict_mfccs_train_validation_test_signal.items():    \n",
    "    arr_mfccs_data = val.transpose()    \n",
    "    arr_target = np.full((arr_mfccs_data.shape[0], 1), key)   \n",
    "\n",
    "    if arr_train_validation_test_data is None:\n",
    "        arr_train_validation_test_data = arr_mfccs_data\n",
    "        arr_train_validation_test_target = arr_target        \n",
    "    else:       \n",
    "        arr_train_validation_test_data = np.vstack((arr_train_validation_test_data, arr_mfccs_data))\n",
    "        arr_train_validation_test_target = np.vstack((arr_train_validation_test_target, arr_target))\n",
    "\n",
    "print(\"Training+Validation+Test data / target : \", arr_train_validation_test_data.shape, arr_train_validation_test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "now_date_time = now.strftime('%Y%m%d_%H%M%S')[2:]\n",
    "\n",
    "CV = 10\n",
    "\n",
    "list_max_iter = [10000]\n",
    "list_C = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 50,0, 100.0, 500.0, 1000.0]  \n",
    "list_gamma = ['scale', 'auto']\n",
    "\n",
    "b_standardscaler = True\n",
    "\n",
    "# list_C = np.arange(5.0, 31.0, 1.0)\n",
    "# list_gamma = np.arange(0.005, 0.016, 0.001)\n",
    "PARAMETERS = {'model__max_iter': list_max_iter, 'model__C': list_C, 'model__gamma': list_gamma}\n",
    "report, params = classifier.gridsearchCV_svm(KERNEL, CV, PARAMETERS, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "save_grid_classification_performance(report, params, now_date_time, b_standardscaler)\n",
    "\n",
    "b_standardscaler = False\n",
    "\n",
    "PARAMETERS = {'max_iter': list_max_iter, 'C': list_C, 'gamma': list_gamma}\n",
    "report, params = classifier.gridsearchCV_svm(KERNEL, CV, PARAMETERS, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "save_grid_classification_performance(report, params, now_date_time, b_standardscaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
