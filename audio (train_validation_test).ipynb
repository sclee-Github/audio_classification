{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import import_ipynb\n",
    "import preprocessor\n",
    "import display\n",
    "import classifier\n",
    "import csv_file_io\n",
    "import datetime\n",
    "\n",
    "PROJECT_HOME = './'\n",
    "# DRONE = 'Inspire2' # 'Bebop2', 'Spark', 'MavicPro', 'Phantom4', 'Matrice100', 'MavicAir', 'AutelEVO', 'Inspire2', 'JME', 'ParrotAnafi']\n",
    "# DATASET_DIR = PROJECT_HOME + 'dataset/validation/Inspire2/Inspire2_validation_File3.wav'\n",
    "RESULT_FILE_DIR = PROJECT_HOME + 'results/'\n",
    "DATASET_FILE_DIR = PROJECT_HOME + 'results/dataset/'\n",
    "TRAINING_DATASET_DIR = PROJECT_HOME + 'dataset/1. training/'\n",
    "VALIDATION_DATASET_DIR = PROJECT_HOME + 'dataset/2. validation/'\n",
    "TEST_DATASET_DIR = PROJECT_HOME + 'dataset/3. test/'\n",
    "TRAINING_VALIDATION_DATASET_DIR = PROJECT_HOME + 'dataset/4. training_validation/'\n",
    "TRAINING_VALIDATION_TEST_DATASET_DIR = PROJECT_HOME + 'dataset/5. training_validation_test/'\n",
    "SEGMENTATION_DATASET_DIR = PROJECT_HOME + 'dataset/6. segmentation/'\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "now_date_time = now.strftime('%Y%m%d_%H%M%S')[2:]\n",
    "\n",
    "RESULT_FILE_NAME = \"[Training+Validation+Test] Classification result ()\"\n",
    "DATASET_FILE_NAME = \"Dataset \"\n",
    "\n",
    "SAMPLE_RATE = 44100\n",
    "FIG_SIZE = (15,5)\n",
    "\n",
    "FRAME_LENGTH = 0.250 # 250 ms\n",
    "FRAME_STRIDE = 0.250 # same with frame_length for 0% overlap\n",
    "\n",
    "DIGITS = 3\n",
    "\n",
    "b_visualizing = False\n",
    "\n",
    "def save_each_classification_performance(kernel: str, target: list, acc: float, tpr: float, fnr: float, tnr: float, fpr: float):\n",
    "    file_name = RESULT_FILE_NAME.split(')')[0] + kernel + ') '\n",
    "\n",
    "    f = csv_file_io.open_csv(RESULT_FILE_DIR + file_name + now_date_time + '.csv', 'w')\n",
    "    csv_file_io.write_csv_data(f, ['Kernel', kernel])\n",
    "    csv_file_io.write_csv_data(f, ['ACC', acc])\n",
    "    csv_file_io.write_csv_data(f, ['', 'TPR', 'FNR', 'TNR', 'FPR'])\n",
    "    \n",
    "    for i in range (0, len(target)):\n",
    "        csv_file_io.write_csv_data(f, [target[i], tpr[i], fnr[i], tnr[i], fpr[i]])    \n",
    "\n",
    "    csv_file_io.write_csv_data(f, [])\n",
    "    csv_file_io.write_csv_data(f, ['Average', round(np.mean(tpr), DIGITS), round(np.mean(fnr), DIGITS), round(np.mean(tnr), DIGITS), round(np.mean(fpr), DIGITS)])\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    # f = csv_file_io.open_csv(RESULT_FILE_DIR + file_name + now_date_time + '.csv', 'a')\n",
    "    # csv_file_io.write_csv_data(f, [kernel, acc, tpr, fnr, tnr, fpr])\n",
    "    # f.close()\n",
    "\n",
    "\n",
    "def save_total_classification_performance(res_dict: dict):\n",
    "    file_name = RESULT_FILE_NAME.split(')')[0] + 'total) '\n",
    "    f = csv_file_io.open_csv(RESULT_FILE_DIR + file_name + now_date_time + '.csv', 'w')\n",
    "    csv_file_io.write_csv_data(f, ['Kernel', 'ACC', 'TPR', 'FNR', 'TNR', 'FPR'])\n",
    "    # f.close()\n",
    "\n",
    "    for i in range(0, len(res_dict['kernel'])):\n",
    "        # f = csv_file_io.open_csv(RESULT_FILE_DIR + FILE_NAME + now_date_time + '.csv', 'a')\n",
    "        csv_file_io.write_csv_data(f, [res_dict['kernel'][i], res_dict['acc'][i],  res_dict['tpr'][i], res_dict['fnr'][i], res_dict['tnr'][i], res_dict['fpr'][i]])    \n",
    "\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_integrated_train_validation_test_signal = preprocessor.get_integrated_signal(SEGMENTATION_DATASET_DIR, type='SEGMENTATION')\n",
    "\n",
    "# Visualizing Audio (waveform and power spectrum)\n",
    "if b_visualizing == True:\n",
    "    for key, val in dict_integrated_train_validation_test_signal.items():\n",
    "        display.display_waveshow(val, key + \"'s Training+Validation+Test Signal's Waveform\")\n",
    "        display.display_power_spectrum(val, key + \"'s Training+Validation+Test Signal's Power Spectrum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction (MFCC)\n",
    "N_MFCC = 40\n",
    "n_fft = int(SAMPLE_RATE * FRAME_LENGTH) # length of the FFT window, frame 하나당 sample의 수 / n_fft=2048, n_fft = int(SAMPLE_RATE * FRAME_LENGTH)\n",
    "hop_length = int(SAMPLE_RATE * FRAME_STRIDE) # number of samples between successive frames / hop_length=512, hop_length = int(SAMPLE_RATE * FRAME_STRIDE)\n",
    "n_mels = 128\n",
    "f_max = 8000\n",
    "\n",
    "dict_melspectrogram_train_validation_test_signal = {}\n",
    "for key, val in dict_integrated_train_validation_test_signal.items():    \n",
    "    dict_melspectrogram_train_validation_test_signal[key] = librosa.feature.melspectrogram(val, sr=SAMPLE_RATE, n_mels=n_mels, fmax=f_max, n_fft=n_fft, hop_length=hop_length)    \n",
    "\n",
    "dict_mfccs_train_validation_test_signal = {}\n",
    "for key, val in dict_melspectrogram_train_validation_test_signal.items():\n",
    "    dict_mfccs_train_validation_test_signal[key] = librosa.feature.mfcc(S=librosa.power_to_db(val), sr=SAMPLE_RATE, n_mfcc=N_MFCC)\n",
    "\n",
    "# print(dict_melspectrogram_train_validation_test_signal['AutelEVO'].shape)\n",
    "# print(dict_mfccs_train_validation_test_signal['AutelEVO'].shape)\n",
    "\n",
    "if b_visualizing == True:\n",
    "    for key, val in dict_mfccs_train_validation_test_signal.items():\n",
    "        display.display_mfccs(val,  \"'s Training+Validation+Test Signal's MFCCs\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_train_validation_test_data = None\n",
    "arr_train_validation_test_target = None\n",
    "\n",
    "for key, val in dict_mfccs_train_validation_test_signal.items():    \n",
    "    arr_mfccs_data = val.transpose()    \n",
    "    arr_target = np.full((arr_mfccs_data.shape[0], 1), key)   \n",
    "\n",
    "    if arr_train_validation_test_data is None:\n",
    "        arr_train_validation_test_data = arr_mfccs_data\n",
    "        arr_train_validation_test_target = arr_target        \n",
    "    else:       \n",
    "        arr_train_validation_test_data = np.vstack((arr_train_validation_test_data, arr_mfccs_data))\n",
    "        arr_train_validation_test_target = np.vstack((arr_train_validation_test_target, arr_target))\n",
    "\n",
    "print(\"Training+Validation+Test data / target : \", arr_train_validation_test_data.shape, arr_train_validation_test_target.shape)\n",
    "ararr_train_validation_test_data_target = np.hstack((arr_train_validation_test_data, arr_train_validation_test_target))\n",
    "# np.savetxt(DATASET_FILE_DIR + DATASET_FILE_NAME + now_date_time + '.csv', ararr_train_validation_test_data_target, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arr_std_train_validation_test_data = classifier.set_scaler_train(arr_train_validation_test_data)\n",
    "\n",
    "CV = 10\n",
    "b_standardscaler = False\n",
    "\n",
    "classifier.cross_validation_svm(\"linear\", CV, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "classifier.cross_validation_svm(\"LinearSVC\", CV, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "classifier.cross_validation_svm(\"rbf\", CV, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "classifier.cross_validation_svm(\"poly\", CV, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "classifier.cross_validation_svm(\"sigmoid\", CV, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_standardscaler = True\n",
    "\n",
    "classifier.cross_validation_svm(\"linear\", CV, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "classifier.cross_validation_svm(\"LinearSVC\", CV, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "classifier.cross_validation_svm(\"rbf\", CV, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "classifier.cross_validation_svm(\"poly\", CV, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "classifier.cross_validation_svm(\"sigmoid\", CV, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_standardscaler = True\n",
    "CV = 10\n",
    "\n",
    "list_C = np.arange(0.01, 5.01, 0.10)\n",
    "PARAMETERS = {'C': list_C} # PARAMETERS = {'C': [0.001, 0.01, 0.1, 1, 10, 25, 50, 100]}\n",
    "classifier.gridsearchCV_svm(\"linear\", CV, PARAMETERS, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "classifier.gridsearchCV_svm(\"LinearSVC\", CV, PARAMETERS, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "\n",
    "# gamma: rbf, poly, sigmoid / degree: poly\n",
    "list_C = np.arange(5.0, 31.0, 1.0)\n",
    "list_gamma = np.arange(0.005, 0.016, 0.001)\n",
    "PARAMETERS = {'C': list_C, 'gamma': list_gamma} # PARAMETERS = {'C': [0.001, 0.01, 0.1, 1, 10, 25, 50, 100], 'gamma':[0.001, 0.01, 0.1, 1, 10, 25, 50, 100]}\n",
    "classifier.gridsearchCV_svm(\"rbf\", CV, PARAMETERS, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "\n",
    "list_C = np.arange(20.0, 71.0, 1.0)\n",
    "list_gamma = np.arange(0.005, 0.016, 0.001)\n",
    "PARAMETERS = {'C': list_C, 'gamma': list_gamma}\n",
    "classifier.gridsearchCV_svm(\"poly\", CV, PARAMETERS, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "\n",
    "list_C = np.arange(20.0, 71.0, 1.0)\n",
    "list_gamma = np.arange(0.0005, 0.0016, 0.0001)\n",
    "PARAMETERS = {'C': list_C, 'gamma': list_gamma}\n",
    "classifier.gridsearchCV_svm(\"sigmoid\", CV, PARAMETERS, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_standardscaler = False\n",
    "CV = 10\n",
    "\n",
    "list_C = np.arange(0.01, 5.01, 0.10)\n",
    "PARAMETERS = {'C': list_C}\n",
    "classifier.gridsearchCV_svm(\"linear\", CV, PARAMETERS, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "classifier.gridsearchCV_svm(\"LinearSVC\", CV, PARAMETERS, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "\n",
    "# gamma: rbf, poly, sigmoid / degree: poly\n",
    "list_C = np.arange(5.0, 31.0, 1.0)\n",
    "list_gamma = np.arange(0.005, 0.016, 0.001)\n",
    "PARAMETERS = {'C': list_C, 'gamma': list_gamma}\n",
    "classifier.gridsearchCV_svm(\"rbf\", CV, PARAMETERS, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "\n",
    "list_C = np.arange(20.0, 71.0, 1.0)\n",
    "list_gamma = np.arange(0.005, 0.016, 0.001)\n",
    "PARAMETERS = {'C': list_C, 'gamma': list_gamma}\n",
    "classifier.gridsearchCV_svm(\"poly\", CV, PARAMETERS, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)\n",
    "\n",
    "list_C = np.arange(20.0, 71.0, 1.0)\n",
    "list_gamma = np.arange(0.0005, 0.0016, 0.0001)\n",
    "PARAMETERS = {'C': list_C, 'gamma': list_gamma}\n",
    "classifier.gridsearchCV_svm(\"sigmoid\", CV, PARAMETERS, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = 10\n",
    "\n",
    "# gamma: rbf, poly, sigmoid / degree: poly\n",
    "list_C = np.arange(5.0, 31.0, 1.0)\n",
    "list_gamma = np.arange(0.005, 0.016, 0.001)\n",
    "PARAMETERS = {'C': list_C, 'gamma': list_gamma}\n",
    "# PARAMETERS = {'C': [0.001, 0.01, 0.1, 1, 10, 25, 50, 100],\\\n",
    "#               'gamma':[0.001, 0.01, 0.1, 1, 10, 25, 50, 100]}\n",
    "\n",
    "classifier.gridsearchCV_svm(\"rbf\", CV, PARAMETERS, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = 10\n",
    "\n",
    "list_C = np.arange(20.0, 71.0, 1.0)\n",
    "list_gamma = np.arange(0.005, 0.016, 0.001)\n",
    "PARAMETERS = {'C': list_C, 'gamma': list_gamma}\n",
    "\n",
    "classifier.gridsearchCV_svm(\"poly\", CV, PARAMETERS, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = 10\n",
    "\n",
    "list_C = np.arange(20.0, 71.0, 1.0)\n",
    "list_gamma = np.arange(0.0005, 0.0016, 0.0001)\n",
    "PARAMETERS = {'C': list_C, 'gamma': list_gamma}\n",
    "\n",
    "classifier.gridsearchCV_svm(\"sigmoid\", CV, PARAMETERS, arr_train_validation_test_data, arr_train_validation_test_target, b_standardscaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
